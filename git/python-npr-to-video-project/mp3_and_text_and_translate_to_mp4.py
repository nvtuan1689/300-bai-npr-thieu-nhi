#!/usr/bin/env python3
"""
MP3 and Text to MP4 Video Generator - T·∫°o video t·ª´ audio v√† transcript song ng·ªØ
T√°c gi·∫£: Script t·ª± ƒë·ªông
Ng√†y t·∫°o: 2026-01-02
"""

import json
from pathlib import Path
from moviepy.editor import *
from PIL import Image, ImageDraw, ImageFont
import numpy as np


def split_text_into_chunks(text, chunk_size=300):
    """Chia text th√†nh c√°c chunk nh·ªè ƒë·ªÉ hi·ªÉn th·ªã"""
    # Chia theo paragraph tr∆∞·ªõc
    paragraphs = text.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) < chunk_size:
            current_chunk += para + '\n\n'
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para + '\n\n'
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks


def wrap_text(text, font, max_width, draw):
    """Wrap text ƒë·ªÉ v·ª´a trong chi·ªÅu r·ªông cho tr∆∞·ªõc"""
    lines = []
    words = text.split()
    current_line = []
    
    for word in words:
        # Th·ª≠ th√™m word v√†o d√≤ng hi·ªán t·∫°i
        test_line = ' '.join(current_line + [word])
        bbox = draw.textbbox((0, 0), test_line, font=font)
        width = bbox[2] - bbox[0]
        
        if width <= max_width:
            current_line.append(word)
        else:
            # D√≤ng ƒë√£ ƒë·∫ßy, l∆∞u l·∫°i v√† b·∫Øt ƒë·∫ßu d√≤ng m·ªõi
            if current_line:
                lines.append(' '.join(current_line))
                current_line = [word]
            else:
                # Word qu√° d√†i, b·∫Øt bu·ªôc ph·∫£i xu·ªëng d√≤ng
                lines.append(word)
    
    # Th√™m d√≤ng cu·ªëi c√πng
    if current_line:
        lines.append(' '.join(current_line))
    
    return '\n'.join(lines)


def create_scrolling_text_frame(full_text_en, full_text_vi, highlight_start, highlight_end, 
                                width=1920, height=1080, font_size_en=32, font_size_vi=28):
    """
    T·∫°o frame v·ªõi to√†n b·ªô text v√† highlight ph·∫ßn ƒëang ƒë·ªçc
    
    Args:
        full_text_en: To√†n b·ªô text ti·∫øng Anh
        full_text_vi: To√†n b·ªô text ti·∫øng Vi·ªát
        highlight_start: V·ªã tr√≠ b·∫Øt ƒë·∫ßu highlight (index)
        highlight_end: V·ªã tr√≠ k·∫øt th√∫c highlight (index)
    """
    # T·∫°o background ƒëen
    img = Image.new('RGB', (width, height), color=(0, 0, 0))
    draw = ImageDraw.Draw(img)
    
    # Fonts
    try:
        font_en = ImageFont.truetype("arial.ttf", font_size_en)
        font_vi = ImageFont.truetype("arial.ttf", font_size_vi)
        font_header = ImageFont.truetype("arial.ttf", 28)
    except:
        font_en = ImageFont.load_default()
        font_vi = ImageFont.load_default()
        font_header = ImageFont.load_default()
    
    # V√πng text
    left_x = 50
    right_x = width // 2 + 50
    y_start = 100
    max_width = width // 2 - 100
    line_spacing = 10
    
    # Wrap to√†n b·ªô text
    wrapped_en = wrap_text(full_text_en, font_en, max_width, draw)
    wrapped_vi = wrap_text(full_text_vi, font_vi, max_width, draw)
    
    # T√≠nh to√°n v·ªã tr√≠ c·ªßa highlight trong wrapped text
    # Chia th√†nh c√°c d√≤ng
    lines_en = wrapped_en.split('\n')
    lines_vi = wrapped_vi.split('\n')
    
    # T√¨m d√≤ng ch·ª©a highlight (d·ª±a v√†o s·ªë k√Ω t·ª±)
    char_count = 0
    highlight_line_start = 0
    highlight_line_end = len(lines_en) - 1
    
    for i, line in enumerate(lines_en):
        line_char_count = len(line)
        if char_count <= highlight_start < char_count + line_char_count:
            highlight_line_start = i
        if char_count <= highlight_end < char_count + line_char_count:
            highlight_line_end = i
            break
        char_count += line_char_count + 1  # +1 for newline
    
    # T√≠nh scroll offset ƒë·ªÉ gi·ªØ highlight ·ªü gi·ªØa m√†n h√¨nh
    available_height = height - y_start - 100
    line_height = font_size_en + line_spacing
    visible_lines = int(available_height / line_height)
    
    # Scroll ƒë·ªÉ highlight_line ·ªü gi·ªØa m√†n h√¨nh (ho·∫∑c g·∫ßn ƒë·∫ßu n·∫øu ch∆∞a ƒë·ªß text)
    target_line = highlight_line_start
    scroll_offset = max(0, target_line - visible_lines // 3)  # Gi·ªØ highlight ·ªü 1/3 m√†n h√¨nh
    
    # V·∫Ω text English (b√™n tr√°i)
    y_pos = y_start
    for i, line in enumerate(lines_en):
        if i < scroll_offset:
            continue  # Skip lines above visible area
        
        line_y = y_pos + (i - scroll_offset) * line_height
        if line_y > height - 100:
            break  # Stop if below visible area
        
        # Check if this line should be highlighted
        if highlight_line_start <= i <= highlight_line_end:
            # Highlight line
            color = (255, 50, 50)  # ƒê·ªè
            # Draw background for highlight
            bbox = draw.textbbox((left_x, line_y), line, font=font_en)
            draw.rectangle([bbox[0]-5, bbox[1]-3, bbox[2]+5, bbox[3]+3], 
                          fill=(50, 20, 20), outline=(255, 50, 50), width=2)
        else:
            color = (200, 200, 200)  # X√°m nh·∫°t
        
        draw.text((left_x, line_y), line, font=font_en, fill=color)
    
    # V·∫Ω text Vietnamese (b√™n ph·∫£i) - sync scroll v·ªõi English
    y_pos = y_start
    for i, line in enumerate(lines_vi):
        if i < scroll_offset:
            continue
        
        line_y = y_pos + (i - scroll_offset) * line_height
        if line_y > height - 100:
            break
        
        # Highlight c√πng d√≤ng v·ªõi English
        if highlight_line_start <= i <= highlight_line_end:
            color = (255, 100, 100)  # ƒê·ªè nh·∫°t h∆°n
            bbox = draw.textbbox((right_x, line_y), line, font=font_vi)
            draw.rectangle([bbox[0]-5, bbox[1]-3, bbox[2]+5, bbox[3]+3], 
                          fill=(50, 20, 20), outline=(255, 100, 100), width=2)
        else:
            color = (180, 180, 200)  # Xanh x√°m nh·∫°t
        
        draw.text((right_x, line_y), line, font=font_vi, fill=color)
    
    # Header
    draw.rectangle([0, 0, width, 80], fill=(20, 20, 20))
    draw.text((left_x, 30), "English Transcript", font=font_header, fill=(150, 150, 150))
    draw.text((right_x, 30), "B·∫£n d·ªãch ti·∫øng Vi·ªát", font=font_header, fill=(150, 150, 150))
    
    return np.array(img)


def load_timestamps(timestamps_path):
    """Load timestamps t·ª´ file JSON (n·∫øu c√≥)"""
    if Path(timestamps_path).exists():
        with open(timestamps_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


def create_video_with_timestamps(mp3_path, text_en, text_vi, timestamps, output_folder, show_progress=True):
    """T·∫°o video MP4 v·ªõi timestamps ch√≠nh x√°c t·ª´ Whisper - Karaoke style"""
    if show_progress:
        print("\nüé¨ ƒêang t·∫°o video v·ªõi timestamps (karaoke style)...")
    
    # Load audio
    audio_clip = AudioFileClip(mp3_path)
    duration = audio_clip.duration
    
    if show_progress:
        print(f"  Audio duration: {duration:.1f} seconds")
        print(f"  S·ªë segments: {len(timestamps)}")
    
    # D·ªãch to√†n b·ªô text m·ªôt l·∫ßn
    from text_to_vietnamese import translate_text
    if show_progress:
        print("  ƒêang d·ªãch to√†n b·ªô text...")
    text_vi_full = translate_text(text_en, show_progress=False)
    
    # T·∫°o mapping t·ª´ timestamps sang character positions
    char_positions = []
    current_pos = 0
    
    for seg in timestamps:
        seg_text = seg['text'].strip()
        # T√¨m v·ªã tr√≠ c·ªßa segment trong full text
        pos = text_en.find(seg_text, current_pos)
        if pos == -1:
            pos = current_pos  # Fallback
        
        char_positions.append({
            'start_time': seg['start'],
            'end_time': seg['end'],
            'char_start': pos,
            'char_end': pos + len(seg_text)
        })
        current_pos = pos + len(seg_text)
    
    if show_progress:
        print(f"  ƒêang t·∫°o {len(char_positions)} frames v·ªõi karaoke effect...")
    
    # T·∫°o video clips - m·ªói segment m·ªôt frame
    video_clips = []
    
    for i, pos_info in enumerate(char_positions):
        if show_progress:
            print(f"\r  Frame {i+1}/{len(char_positions)}...", end='')
        
        # T·∫°o frame v·ªõi full text v√† highlight segment hi·ªán t·∫°i
        frame = create_scrolling_text_frame(
            text_en, 
            text_vi_full,
            pos_info['char_start'],
            pos_info['char_end']
        )
        
        # Duration = end - start
        seg_duration = pos_info['end_time'] - pos_info['start_time']
        
        # T·∫°o clip t·ª´ frame
        clip = ImageClip(frame).set_duration(seg_duration).set_start(pos_info['start_time'])
        video_clips.append(clip)
    
    if show_progress:
        print()
    
    # Gh√©p c√°c clips
    if show_progress:
        print("  ƒêang gh√©p video...")
    video = CompositeVideoClip(video_clips, size=(1920, 1080))
    
    # Set duration v√† audio
    video = video.set_duration(duration).set_audio(audio_clip)
    
    # Output path
    output_path = Path(output_folder) / "output_video.mp4"
    
    # Render video
    if show_progress:
        print(f"  ƒêang render video: {output_path}")
    video.write_videofile(
        str(output_path),
        fps=24,
        codec='libx264',
        audio_codec='aac',
        temp_audiofile='temp-audio.m4a',
        remove_temp=True,
        verbose=False,
        logger=None
    )
    
    # Cleanup
    audio_clip.close()
    video.close()
    
    if show_progress:
        print(f"‚úÖ ƒê√£ t·∫°o video: {output_path}")
    
    return output_path


def create_video(mp3_path, text_en, text_vi, output_folder, show_progress=True):
    """T·∫°o video MP4 t·ª´ audio v√† text (fallback n·∫øu kh√¥ng c√≥ timestamps)"""
    if show_progress:
        print("\nüé¨ ƒêang t·∫°o video...")
    
    # Check xem c√≥ timestamps kh√¥ng
    timestamps_path = Path(mp3_path).parent / "timestamps.json"
    if timestamps_path.exists():
        if show_progress:
            print(f"‚úÖ T√¨m th·∫•y timestamps.json - s·ª≠ d·ª•ng sync ch√≠nh x√°c!")
        timestamps = load_timestamps(timestamps_path)
        return create_video_with_timestamps(mp3_path, text_en, text_vi, timestamps, output_folder, show_progress)
    
    # Fallback: chia ƒë·ªÅu th·ªùi gian
    if show_progress:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y timestamps.json - s·ª≠ d·ª•ng chia ƒë·ªÅu th·ªùi gian")
        print("  ƒê·ªÉ sync ch√≠nh x√°c h∆°n, ch·∫°y: python mp3_to_transcript_with_timestamps.py <mp3_path>")
    
    # Load audio
    audio_clip = AudioFileClip(mp3_path)
    duration = audio_clip.duration
    
    if show_progress:
        print(f"  Audio duration: {duration:.1f} seconds")
    
    # Chia text th√†nh chunks (gi·∫£m chunk_size ƒë·ªÉ sync t·ªët h∆°n v·ªõi audio)
    chunks_en = split_text_into_chunks(text_en, chunk_size=200)
    chunks_vi = split_text_into_chunks(text_vi, chunk_size=200)
    
    # ƒê·∫£m b·∫£o 2 list c√≥ c√πng ƒë·ªô d√†i
    max_chunks = max(len(chunks_en), len(chunks_vi))
    while len(chunks_en) < max_chunks:
        chunks_en.append("")
    while len(chunks_vi) < max_chunks:
        chunks_vi.append("")
    
    if show_progress:
        print(f"  S·ªë chunks: {max_chunks}")
    
    # Th·ªùi gian cho m·ªói chunk
    time_per_chunk = duration / max_chunks
    
    # T·∫°o video clips
    video_clips = []
    
    for i, (chunk_en, chunk_vi) in enumerate(zip(chunks_en, chunks_vi)):
        if show_progress:
            print(f"\r  ƒêang t·∫°o frame {i+1}/{max_chunks}...", end='')
        
        # T·∫°o frame v·ªõi highlight
        frame = create_text_frame(chunk_en, chunk_vi, highlight_en=True, highlight_vi=True)
        
        # T·∫°o clip t·ª´ frame
        clip = ImageClip(frame).set_duration(time_per_chunk)
        video_clips.append(clip)
    
    if show_progress:
        print()
    
    # Gh√©p c√°c clips
    if show_progress:
        print("  ƒêang gh√©p video...")
    video = concatenate_videoclips(video_clips, method="compose")
    
    # Th√™m audio
    video = video.set_audio(audio_clip)
    
    # Output path
    output_path = Path(output_folder) / "output_video.mp4"
    
    # Render video
    if show_progress:
        print(f"  ƒêang render video: {output_path}")
    video.write_videofile(
        str(output_path),
        fps=24,
        codec='libx264',
        audio_codec='aac',
        temp_audiofile='temp-audio.m4a',
        remove_temp=True,
        verbose=False,
        logger=None
    )
    
    # Cleanup
    audio_clip.close()
    video.close()
    
    if show_progress:
        print(f"‚úÖ ƒê√£ t·∫°o video: {output_path}")
    
    return output_path


def main():
    """Main function - standalone usage"""
    import sys
    
    if len(sys.argv) < 4:
        print("Usage: python mp3_and_text_and_translate_to_mp4.py <mp3_path> <text_en> <text_vi> [output_folder]")
        sys.exit(1)
    
    mp3_path = sys.argv[1]
    text_en_path = sys.argv[2]
    text_vi_path = sys.argv[3]
    output_folder = sys.argv[4] if len(sys.argv) > 4 else Path(mp3_path).parent
    
    # ƒê·ªçc text
    with open(text_en_path, 'r', encoding='utf-8') as f:
        text_en = f.read()
    
    with open(text_vi_path, 'r', encoding='utf-8') as f:
        text_vi = f.read()
    
    # T·∫°o video
    video_path = create_video(mp3_path, text_en, text_vi, output_folder)
    
    print(f"\n‚úÖ Ho√†n th√†nh! Video: {video_path}")


if __name__ == "__main__":
    main()
