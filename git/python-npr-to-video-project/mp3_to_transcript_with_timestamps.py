#!/usr/bin/env python3
"""
MP3 to Transcript with Timestamps - S·ª≠ d·ª•ng Whisper AI (offline)
T√°c gi·∫£: Script t·ª± ƒë·ªông
Ng√†y t·∫°o: 2026-01-02

T·∫°o transcript v·ªõi timestamps ch√≠nh x√°c t·ª´ audio MP3 s·ª≠ d·ª•ng Whisper AI
"""

import sys
import json
from pathlib import Path


def transcribe_audio_with_timestamps(mp3_path, model_size="base", language="en"):
    """
    Transcribe audio v√† t·∫°o timestamps
    
    Args:
        mp3_path: Path ƒë·∫øn file MP3
        model_size: K√≠ch th∆∞·ªõc model Whisper (tiny, base, small, medium, large)
        language: Ng√¥n ng·ªØ (en, vi, etc.)
    
    Returns:
        segments: List c√°c segment v·ªõi text v√† timestamps
    """
    print(f"\nüéôÔ∏è ƒêang transcribe audio v·ªõi Whisper AI (model: {model_size})...")
    
    try:
        import whisper
        import torch
        
        # Load model v·ªõi weights_only=False ƒë·ªÉ t∆∞∆°ng th√≠ch PyTorch 2.6
        print(f"  ƒêang load model '{model_size}'...")
        
        # Monkey patch torch.load ƒë·ªÉ fix PyTorch 2.6 compatibility
        original_load = torch.load
        def patched_load(*args, **kwargs):
            kwargs['weights_only'] = False
            return original_load(*args, **kwargs)
        torch.load = patched_load
        
        model = whisper.load_model(model_size)
        
        # Restore original torch.load
        torch.load = original_load
        
        # Transcribe
        print(f"  ƒêang transcribe: {mp3_path}")
        print(f"  ‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...")
        
        result = model.transcribe(
            str(mp3_path),  # Convert to string to ensure compatibility
            language=language,
            verbose=False,
            word_timestamps=False  # T·∫Øt word_timestamps ƒë·ªÉ tr√°nh l·ªói
        )
        
        # Extract segments
        segments = []
        for segment in result['segments']:
            segments.append({
                'start': segment['start'],
                'end': segment['end'],
                'text': segment['text'].strip()
            })
        
        print(f"‚úÖ ƒê√£ transcribe: {len(segments)} segments")
        
        return segments
    
    except ImportError:
        print("‚ùå Th∆∞ vi·ªán 'openai-whisper' ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t!")
        print("  C√†i ƒë·∫∑t: pip install openai-whisper")
        sys.exit(1)
    except FileNotFoundError as e:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file ho·∫∑c thi·∫øu ffmpeg!")
        print(f"  Chi ti·∫øt: {e}")
        print("\nüí° Gi·∫£i ph√°p:")
        print("  1. Ki·ªÉm tra file MP3 c√≥ t·ªìn t·∫°i: {mp3_path}")
        print("  2. C√†i ƒë·∫∑t ffmpeg:")
        print("     - Download: https://ffmpeg.org/download.html")
        print("     - Ho·∫∑c: https://github.com/BtbN/FFmpeg-Builds/releases")
        print("     - Th√™m ffmpeg.exe v√†o PATH ho·∫∑c folder hi·ªán t·∫°i")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå L·ªói khi transcribe: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå L·ªói khi transcribe: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def save_segments_to_json(segments, output_path):
    """L∆∞u segments v√†o file JSON"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(segments, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ ƒê√£ l∆∞u timestamps: {output_path}")


def save_segments_to_txt(segments, output_path):
    """L∆∞u segments v√†o file TXT (d·∫°ng SRT)"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments, 1):
            start_time = format_timestamp(seg['start'])
            end_time = format_timestamp(seg['end'])
            f.write(f"{i}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{seg['text']}\n\n")
    
    print(f"‚úÖ ƒê√£ l∆∞u transcript: {output_path}")


def format_timestamp(seconds):
    """Format gi√¢y th√†nh HH:MM:SS,mmm"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def main():
    """Main function - standalone usage"""
    if len(sys.argv) < 2:
        print("Usage: python mp3_to_transcript_with_timestamps.py <mp3_path> [model_size]")
        print("Model sizes: tiny, base, small, medium, large")
        print("  tiny  - Nhanh nh·∫•t, √≠t ch√≠nh x√°c (~1GB RAM)")
        print("  base  - C√¢n b·∫±ng (recommended, ~1GB RAM)")
        print("  small - Ch√≠nh x√°c h∆°n (~2GB RAM)")
        print("  medium - R·∫•t ch√≠nh x√°c (~5GB RAM)")
        print("  large - Ch√≠nh x√°c nh·∫•t (~10GB RAM)")
        sys.exit(1)
    
    mp3_path = sys.argv[1]
    model_size = sys.argv[2] if len(sys.argv) > 2 else "base"
    
    # Validate file
    if not Path(mp3_path).exists():
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {mp3_path}")
        sys.exit(1)
    
    # Transcribe
    segments = transcribe_audio_with_timestamps(mp3_path, model_size=model_size)
    
    # Save outputs
    mp3_file = Path(mp3_path)
    output_folder = mp3_file.parent
    
    json_path = output_folder / "timestamps.json"
    txt_path = output_folder / "transcript_with_timestamps.txt"
    
    save_segments_to_json(segments, json_path)
    save_segments_to_txt(segments, txt_path)
    
    print(f"\n‚úÖ Ho√†n th√†nh!")
    print(f"  JSON: {json_path}")
    print(f"  TXT: {txt_path}")


if __name__ == "__main__":
    main()
